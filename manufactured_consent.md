# Manufactured Consent
## The Next Era of Prompt Engineering

Prompting with Logical Expressions using Propositional, Predicate & Modal Logic

Author: Michael Jagdeo | Blockface | [attractfund1ng](http://www.twitter.com/attractfund1ng)

Contributors: Mnemomeme, Fratrilogos, Oma Cox, BeatCheek, Rocky Nguyen, Seraph_Notitia, Quinn C. Martin, Potato Stu, Eileen Jan, Ayden Springer, Matios Berhe, Liminal Snake

## Background

[The Prompt Report: A Systematic Survey of Prompting Techniques](https://arxiv.org/pdf/2406.06608) (June 2024), claimed the following:
> We present a detailed vocabulary of 33 vocabulary terms, a taxonomy of 58 LLM prompting techniques, and 40 techniques for other modalities. Additionally, we provide best practices and guidelines for prompt engineering, including advice for prompting engineering ChatGPT and other state-of-the-art (SOTA) LLMs. We further present a meta-analysis of the entire literature on natural language prefix-prompting. As a culmination of these efforts, this paper presents the most comprehensive survey on prompt engineering to date.

## Motivation

That paper overlooked the most powerful way to manufacture consent from LLMs, namely, prompting with propositional, predicate, and modal logic.

## The Last 100 Years Of Math

At the turn of the 20th century, Hilbert proposes a bunch of unsolved problems in math. Standing on the shoulders of giants like Frege, Whitehead & Russell write Principia Mathematica (named after Newton’s Principia), seeking to create a cathedral of logic. Godel proves you can’t do it.

As a result of Godel’s anti-thesis to the Princiipia Mathematica, Turing and Church create the Church-Turing Thesis as a result of Godel’s discoveries. Chomsky and Von Neuemann ensue to create software development languages.

## Motivation II

The reason that people don't get what they want when they prompt LLMs is they're using the wrong language. They use natural language, i.e. sentences. The problem is, LLMs must translate these user queries into forms that the LLM can parse. By using logical expressions leveraging propositional, predicate, and modal logic, we can create a significantly better quality of result while reducing token usage across all LLMs

## Next Time You Prompt...

Try starting with this prompt:
> I'd like to have a conversation with you, where at every step we update a logical expression that leverages predicate propositional and modal logic.

## Rationale

Prompting with predicate and propositional and modal logic offers a more precise and structured approach compared to natural language, leading to focused outputs with minimal token usage. Unlike natural language prompts, which can introduce ambiguity and require longer explanations to clarify intent, logic-based prompts reduce redundancy and optimize both computational efficiency and output quality. By expressing queries through formalized logical structures, we minimize unnecessary complexity, making interactions with Large Language Models (LLMs) more effective. This paper explores how leveraging predicate and propositional logic in prompt engineering can significantly improve response relevance, clarity, and performance. Furthermore, we discuss novel methods for implementing these approaches, including the development of predicate and propositional logic pre-processors that can optimize token usage, improve response quality, and reduce computational overhead. These advancements provide a more efficient method for engaging with LLMs, resulting in significant cost savings across compute, network, storage, bandwidth, and AI inference latency. These findings work with ALL LLMs.
